{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "with open(\"/Users/ghidav/Desktop/keys.json\") as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = keys[\"huggingface\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789f34bb32c44995a2af0a10cb538cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'layers.9' downloaded to 'saes/pythia-160pm-deduped/jr/baseline/9'.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the repository ID and target folder\n",
    "repo_id = \"mech-interp/baselines-jr-target-l0-pythia-160m-deduped\"\n",
    "subfolder = \"layers.9\"\n",
    "local_save_path = \"saes/pythia-160pm-deduped/jr/baseline/9\"\n",
    "\n",
    "# Download the entire repo snapshot temporarily\n",
    "repo_path = snapshot_download(repo_id=repo_id, allow_patterns=f\"{subfolder}/*\")\n",
    "\n",
    "# Copy only the desired subfolder to the local directory\n",
    "subfolder_path = os.path.join(repo_path, subfolder)\n",
    "if os.path.exists(subfolder_path):\n",
    "    shutil.copytree(subfolder_path, local_save_path, dirs_exist_ok=True)\n",
    "    print(f\"Folder '{subfolder}' downloaded to '{local_save_path}'.\")\n",
    "else:\n",
    "    print(f\"Subfolder '{subfolder}' not found in the repository.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors import safe_open\n",
    "\n",
    "state_dict = safe_open(\"saes/pythia-160pm-deduped/jr/baseline/8/sae.safetensors\", framework=\"torch\")\n",
    "with open(\"saes/pythia-160pm-deduped/jr/baseline/8/cfg.json\", \"r\") as f:\n",
    "    cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['W_dec', 'b_dec', 'encoder.bias', 'encoder.weight', 'log_threshold'],\n",
       " dict_keys(['expansion_factor', 'normalize_decoder', 'num_latents', 'k', 'multi_topk', 'jumprelu', 'jumprelu_init_threshold', 'jumprelu_bandwidth', 'jumprelu_target_l0', 'init_enc_as_dec_transpose', 'init_b_dec_as_zeros', 'd_in']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys(), cfg.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aether.encoder import FFEncoder\n",
    "from aether.decoder import FFDecoder\n",
    "from aether.core import AE\n",
    "from aether.functions import JumpReLU\n",
    "\n",
    "class JumpReLSAE(AE):\n",
    "    def __init__(self, input_dim, latent_dim, output_dim):\n",
    "        encoder = FFEncoder(input_dim, latent_dim)\n",
    "        decoder = FFDecoder(latent_dim, output_dim)\n",
    "        super().__init__(encoder, decoder, JumpReLU(latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_latents = cfg[\"num_latents\"] if cfg[\"num_latents\"] > 0 else cfg[\"d_in\"] * cfg[\"expansion_factor\"]\n",
    "sae = JumpReLSAE(cfg[\"d_in\"], num_latents, cfg[\"d_in\"])\n",
    "sae.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state_dict = {\n",
    "    \"encoder.fc.weight\": state_dict.get_tensor(\"encoder.weight\"),\n",
    "    \"encoder.fc.bias\": state_dict.get_tensor(\"encoder.bias\"),\n",
    "    \"decoder.fc.weight\": state_dict.get_tensor(\"W_dec\").T,\n",
    "    \"decoder.fc.bias\": state_dict.get_tensor(\"b_dec\"),\n",
    "    \"F.log_threshold\": state_dict.get_tensor(\"log_threshold\"),\n",
    "}\n",
    "\n",
    "sae.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12288, 768])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_dec = sae.decoder.fc.weight.cpu().detach().clone().T\n",
    "W_dec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from aether.data import LMGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dfacdfe658146f3bf58a789f6db6312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm = AutoModelForCausalLM.from_pretrained('EleutherAI/pythia-160m-deduped')\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/pythia-160m-deduped')\n",
    "\n",
    "dataset = load_dataset('EleutherAI/the_pile_deduplicated', split='train', streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50304, 768])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_U = lm.embed_out.weight.cpu().detach().clone()\n",
    "W_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "batch_size = 16\n",
    "\n",
    "gen = LMGenerator(\n",
    "    lm=lm,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    column=\"text\",\n",
    "    seq_len=seq_len,\n",
    "    hookpoints=[\"layers.3\"],\n",
    "    batch_size=batch_size,\n",
    "    device=\"mps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "act_dict = {\"layers.3\": []}\n",
    "tokens = []\n",
    "\n",
    "n_batches = 2\n",
    "\n",
    "for act_dict_, tokens_ in gen:\n",
    "    for k, v in act_dict_.items():\n",
    "        act_dict[k].append(v)\n",
    "    tokens.append(tokens_)\n",
    "    if len(tokens) >= n_batches:\n",
    "        break\n",
    "\n",
    "act_dict[\"layers.3\"] = torch.cat(act_dict[\"layers.3\"], dim=0)\n",
    "tokens = torch.cat(tokens, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output, latents = sae(act_dict[\"layers.3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ids = torch.randint(0, latents.size(1), (128,))\n",
    "selected_latents = latents[:, f_ids]\n",
    "\n",
    "W_dec_selected = W_dec[f_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = batch_size * n_batches\n",
    "selected_latents = selected_latents.reshape(N, seq_len, -1)\n",
    "\n",
    "max_acts, _ = selected_latents.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 32, 128]), torch.Size([32, 32]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_latents.shape, tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 137.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "feature_dataset = {}\n",
    "logit_scores = W_dec_selected @ W_U.T # [F, V]\n",
    "\n",
    "for i, f_id in tqdm(enumerate(f_ids), total=len(f_ids)):\n",
    "    feature_dataset[f_id.item()] = {}\n",
    "\n",
    "    # Cut activations in quantiles: (0.8, 0.9, 0.95, 0.99)\n",
    "    quantiles = max_acts[:, i].quantile(\n",
    "        torch.tensor([0.8, 0.9, 0.95, 0.99], device=max_acts.device)\n",
    "    )\n",
    "\n",
    "    lower_bound = quantiles[0]\n",
    "    for j, (quantile, label) in enumerate(\n",
    "        zip(quantiles[1:], [\"80-90\", \"90-95\", \"95-99\"])\n",
    "    ):\n",
    "        mask = max_acts[:, i] > lower_bound\n",
    "        mask &= max_acts[:, i] <= quantile\n",
    "\n",
    "        sent_tokens = tokens[mask.cpu()].tolist()\n",
    "        latent_acts = selected_latents[mask, :, i].cpu().tolist()\n",
    "\n",
    "        # Zip tokens and activations, then sample at most 5\n",
    "        zipped_data = list(zip(sent_tokens, latent_acts))\n",
    "        sampled_data = random.sample(zipped_data, min(5, len(zipped_data)))\n",
    "\n",
    "        feature_dataset[f_id.item()][label] = sampled_data\n",
    "        lower_bound = quantile\n",
    "\n",
    "    mask = max_acts[:, i] > lower_bound\n",
    "    sent_tokens = tokens[mask.cpu()].tolist()\n",
    "    latent_acts = selected_latents[mask, :, i].cpu().tolist()\n",
    "\n",
    "    # Zip tokens and activations, then sample at most 5 for \"99-100\"\n",
    "    zipped_data = list(zip(sent_tokens, latent_acts))\n",
    "    sampled_data = random.sample(zipped_data, min(5, len(zipped_data)))\n",
    "\n",
    "    # Find top and bottom token by attribution\n",
    "    top_val, top_ids = torch.topk(logit_scores[i], 10)\n",
    "    bottom_val, bottom_ids = torch.topk(-logit_scores[i], 10)\n",
    "\n",
    "    feature_dataset[f_id.item()][\"top_tokens\"] = list(zip(top_ids.tolist(), top_val.tolist()))\n",
    "    feature_dataset[f_id.item()][\"bottom_tokens\"] = list(zip(bottom_ids.tolist(), bottom_val.tolist()))\n",
    "\n",
    "    feature_dataset[f_id.item()][\"99-100\"] = sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature_dataset.json\", \"w\") as f:\n",
    "    json.dump(feature_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
